{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression</h1>\n",
    "In this notebook, we will apply logistic regression (despite having regression in its name, it is referred to as a classification algorithm mainly) on the same boston house dataset. The original dataset was for regression task, we will convert it into a <strong>binary classification</strong> task [hypothetical].\n",
    "\n",
    "1. We will look at hyper-parameter tuning during modelling.\n",
    "2. The evaluation metrics (also loss functions) related to classification task, and their importance in gauging the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>EXPENSIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT EXPENSIVE  \n",
       "0     15.3  396.90   4.98        NO  \n",
       "1     17.8  396.90   9.14        NO  \n",
       "2     17.8  392.83   4.03       YES  \n",
       "3     18.7  394.63   2.94       YES  \n",
       "4     18.7  396.90   5.33       YES  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using boston house price dataset: this is available from sklearn library\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "# changing the target: to convert it into a hypothetical classification algorithm\n",
    "# say, if the PRICE > $300,000 then the house is considered expensive\n",
    "# our classification task is to check if a house will be expensive/not by just looking at the features.\n",
    "df['EXPENSIVE'] = boston['target']\n",
    "df['EXPENSIVE'] = df['EXPENSIVE'].apply(lambda x: 'YES' if x>30 else 'NO')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initial Data Analysis and Explanatory Data Analysis</h1>\n",
    "Similar analysis holds as the <a href='linear_regression_2.ipynb'>previous notebook</a>, and the findings apply here too. We are omitting that part in this notebook but remember this is quite an important step for any ML task. Additionally, in this task, the class balance/imbalance of the target variable should also be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of YES: 16.601%, Proportion of NO: 83.399%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     506\n",
       "unique      2\n",
       "top        NO\n",
       "freq      422\n",
       "Name: EXPENSIVE, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Proportion of YES: {:.3f}%, Proportion of NO: {:.3f}%'.format(df[df['EXPENSIVE']=='YES']['EXPENSIVE'].count()*100/df.shape[0], df[df['EXPENSIVE']=='NO']['EXPENSIVE'].count()*100/df.shape[0]))\n",
    "df['EXPENSIVE'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tasks</h1>\n",
    "\n",
    "In a typical ML task, you actually should reflect here because of the class imbalance - 'Not Expensive' houses dominate the dataset. In an ideal dataset, you should generally  have equal proportion of 'YES' and 'NO' for a binary classification task. If not, you should at least try to resolve it [generating more samples, undersamplling the major class, oversampling the minor class, synthetically create more samples etc.] - all these without comprising the 'validity' of the data, i.e., throwing away important information [undersampling], introducing 'false information' inside the dataset [the way you introduced more samples, etc.]. This is quite an important part, and after completing this notebook, you should try to come back to this step, and may try to resolve this issue and evaluate the model's performance again.\n",
    "\n",
    "For example, without any training, if an estimator just predicts the house as 'NOT EXPENSIVE' for any input, then the model's accuracy will be 83.399% for this dataset!!! Without resolving this imbalance, it is likely that the trained classifier may be inclined towards predicting the house to be 'NOT EXPENSIVE' too since this imbalance will impact its learning.\n",
    "\n",
    "We will proceed with our <strong>binary classification task</strong> anyway without resolving this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modelling (with hyper-parameter tuning)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: LogisticRegression()\n",
      "Weights: [[ 0.14513444  0.39202927 -0.97854289  0.1618424   0.02479979  1.47605734\n",
      "   0.35606539 -0.67879687  0.95373518 -0.49196683 -0.73602807  0.1204218\n",
      "  -2.43396895]], Intercept: [-4.37431992]\n",
      "Best params: {'C': 1.0}\n",
      "Scorer: make_scorer(recall_score, average=binary)\n",
      "Available parameters for the estimator (fine-tuning):  dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") # for GridSearchCV: some of its combination throws warning which is fine (they are not appropriate combination)\n",
    "\n",
    "# dropping the EXPENSIVE column [target variable]\n",
    "X = df.drop(['EXPENSIVE'], axis = 1)\n",
    "#X = df[['RM']] # use/uncomment this line if you want to use a single feature!!!\n",
    "y = df['EXPENSIVE'].apply(lambda x: 0 if x=='NO' else 1) # convering the categorical target into numeric: EXPENSIVE = 1, NOT EXPENSIVE = 0\n",
    "\n",
    "# standardisation of the features: extremely important so that the effect of 'magnitude difference' between features do not affect the optimisation of weights are not given more importance\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# separating of training and testing set: 80-20 separation\n",
    "# random_state parameter is given to keep the same randomised splitting: important when you are creating the model\n",
    "# and want to keep a specific separation across multiple runs. Once modelling/evaluation is completed, you can actually\n",
    "# remove this parameter to generate random splitting in each run of this notebook\n",
    "# for classification, stratification on y [target] is important so that equal proportion of classes exist in both training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# hyper-parameter tuning using in-built GridSearchCV\n",
    "# pipeline is used to standardisation and also creating the normal instance of a LogisticRegression\n",
    "# This may take a while: good to set the max_iter parameter as well...\n",
    "param_grid=[{'C': np.logspace(-4,4,15)},\n",
    "           {'penalty': ['l1', 'l2']},\n",
    "           {'solver': ['lbfgs', 'liblinear', 'adam']},\n",
    "          {'max_iter': [10000]}]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# refer to sklearn documentation for more details:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv=10, scoring='recall', refit=True) # you can change scoring function that will impact the estimator\n",
    "grid = grid.fit(X_train, y_train)\n",
    "print('Best estimator: {}\\nWeights: {}, Intercept: {}\\nBest params: {}\\nScorer: {}'.format(grid.best_estimator_, grid.best_estimator_.coef_, grid.best_estimator_.intercept_,grid.best_params_, grid.scorer_))\n",
    "print('Available parameters for the estimator (fine-tuning): ',lr.get_params().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SET\n",
      "--------------------------------------\n",
      "Accuracy: 0.953, Precision: 0.853, Recall: 0.866, F1 Score: 0.859\n",
      "Confusion Matrix:\n",
      " [[327  10]\n",
      " [  9  58]]\n",
      "\n",
      "Testing SET\n",
      "--------------------------------------\n",
      "Accuracy: 0.961, Precision: 0.882, Recall: 0.882, F1 Score: 0.882\n",
      "Confusion Matrix:\n",
      " [[83  2]\n",
      " [ 2 15]]\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for training set\n",
    "y_train_predict = grid.predict(X_train)\n",
    "print(\"Training SET\")\n",
    "print(\"--------------------------------------\")\n",
    "print('Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, F1 Score: {:.3f}'.format(accuracy_score(y_train, y_train_predict), precision_score(y_train, y_train_predict), recall_score(y_train, y_train_predict), f1_score(y_train, y_train_predict)))\n",
    "print(\"Confusion Matrix:\\n {}\".format(confusion_matrix(y_train, y_train_predict)))\n",
    "\n",
    "# model evaluation for testing set\n",
    "y_test_predict = grid.predict(X_test)\n",
    "\n",
    "print(\"\\nTesting SET\")\n",
    "print(\"--------------------------------------\")\n",
    "print('Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, F1 Score: {:.3f}'.format(accuracy_score(y_test, y_test_predict), precision_score(y_test, y_test_predict), recall_score(y_test, y_test_predict), f1_score(y_test, y_test_predict)))\n",
    "print(\"Confusion Matrix:\\n {}\".format(confusion_matrix(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC (Training)=0.981\n",
      "ROC AUC (Testing)=0.982\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs_train = grid.predict_proba(X_train)\n",
    "lr_probs_test = grid.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs_train = lr_probs_train[:, 1]\n",
    "lr_probs_test = lr_probs_test[:, 1]\n",
    "\n",
    "print('ROC AUC (Training)={:.3f}'.format(roc_auc_score(y_train, lr_probs_train)))\n",
    "print('ROC AUC (Testing)={:.3f}'.format(roc_auc_score(y_test, lr_probs_test)))\n",
    "\n",
    "lr_fpr_train, lr_tpr_train, _ = roc_curve(y_train, lr_probs_train)\n",
    "lr_fpr_test, lr_tpr_test, _ = roc_curve(y_test, lr_probs_test)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "_ = plt.figure(figsize=(15, 5))\n",
    "ax1 =plt.subplot(121)\n",
    "_ = ax1.plot(lr_fpr_train, lr_tpr_train, marker='x')\n",
    "_ = ax1.plot([0,1], [0, 1], 'gray', linestyle=':', marker='')\n",
    "_ = ax1.set_title('Receiver Operating Characteristics (ROC) - Training')\n",
    "_ = ax1.set_xlabel('False Positive Rate')\n",
    "_ = ax1.set_ylabel('True Positive Rate')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "_ = ax2.plot(lr_fpr_test, lr_tpr_test, marker='x')\n",
    "_ = ax2.plot([0,1], [0, 1], 'gray', linestyle=':', marker='')\n",
    "_ = ax2.set_title('Receiver Operating Characteristics (ROC) - Testing')\n",
    "_ = ax2.set_xlabel('False Positive Rate')\n",
    "_ = ax2.set_ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inference Probabilities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPENSIVE</th>\n",
       "      <th>PREDICTED PROBABILITY OF BEING EXPENSIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YES</td>\n",
       "      <td>0.542816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.173117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.254443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>YES</td>\n",
       "      <td>0.802174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.011674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXPENSIVE  PREDICTED PROBABILITY OF BEING EXPENSIVE\n",
       "10       YES                                  0.542816\n",
       "11        NO                                  0.173117\n",
       "12        NO                                  0.003434\n",
       "13        NO                                  0.000922\n",
       "14        NO                                  0.000968\n",
       "15        NO                                  0.254443\n",
       "16       YES                                  0.802174\n",
       "17        NO                                  0.000014\n",
       "18        NO                                  0.000225\n",
       "19        NO                                  0.011674"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(lr_probs_test[0:20])\n",
    "#here, we create a pandas dataframe to demonstrate the computed probabilities for a house of being expensive in order to relate it to the lecture notes\n",
    "#remember, logistic regression's regressed part is on these probabilities!\n",
    "expensive = {1: 'YES', 0:'NO'} # just to revert back y_test's 0,1 numeric to YES/NO categorical values for display\n",
    "pb_df = pd.DataFrame({'EXPENSIVE':[expensive[numeric_cat] for numeric_cat in y_test[0:]], 'PREDICTED PROBABILITY OF BEING EXPENSIVE':lr_probs_test[0:]}, columns=['EXPENSIVE', 'PREDICTED PROBABILITY OF BEING EXPENSIVE'])\n",
    "pb_df.iloc[10:20].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For record X_test[10], our manually computed probability: 0.5428158532370662, sklearn's returned probability: 0.5428158532370662\n",
      "The two false positives are below: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPENSIVE</th>\n",
       "      <th>PREDICTED PROBABILITY OF BEING EXPENSIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.640202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NO</td>\n",
       "      <td>0.509722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXPENSIVE  PREDICTED PROBABILITY OF BEING EXPENSIVE\n",
       "47        NO                                  0.640202\n",
       "58        NO                                  0.509722"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will break down the computation of the first probability here [0.542816] corresponding to the testing record X_test[10:11]\n",
    "# and relate it to the different elements of the logistic regression algorithm [refer to Slide 4 of the lecture notes - especially the diagram]\n",
    "\n",
    "# we already know the optimum weights, w_i [model parameters] after training, they are stored as grid.best_estimator_.coef_ [since we have used Grid Search]\n",
    "# depending on how you train them [with or without grid search], and the name of the variables, this may vary......\n",
    "# grid.best_estimator_.intercept_ will hold the w_0\n",
    "\n",
    "# compute: net input (z): refer to Slide 4 of lecture notes [it is just the weighted sum, z = \\sum_{j=1}^m w_j.x_j + w_0]\n",
    "z = np.dot(X_test[10:11].tolist()[0], grid.best_estimator_.coef_[0])+grid.best_estimator_.intercept_[0]\n",
    "\n",
    "# compute: sigma(z): the probability / activation function output - again refer to Slide 4 of lecture notes....\n",
    "sigma_z = 1 / (1+ np.exp(-z))\n",
    "print(\"For record X_test[10], our manually computed probability: {}, sklearn's returned probability: {}\".format(sigma_z, grid.predict_proba(X_test[10:11])[:,1][0]))\n",
    "\n",
    "# you may also want to look at the False Positive records predicted probabilities [e.g., NO in actual Expensive column but probability of prediction will be >= 0.5]\n",
    "# we already know there will be two False Positives for the testing set [from the confusion matrix above]\n",
    "print('The two false positives are below: ')\n",
    "pb_df[(pb_df['EXPENSIVE'] == 'NO') & (pb_df['PREDICTED PROBABILITY OF BEING EXPENSIVE'] >= 0.5)]\n",
    "# you can trace back to the X_test to check the features [standardised] - you may need to 'de'-standardise to check the actual feature values\n",
    "# also, do the same for false negatives - from confusion matrix, you know there will be two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The increase in odds by increasing 1-unit of average number of rooms (predictor RM) should be: 8.18971\n",
      "The computed gain using the probabilities: 8.18971\n",
      "Means we gain more than 8 times odds of  being an Expensive house by just increasing 1-unit of average number of rooms (RM feature)\n",
      "Similar analysis can be performed regarding other features as well.\n"
     ]
    }
   ],
   "source": [
    "# computing odds (in many books/articles, you may find it to be 'logit' function)\n",
    "# if P(Y==1|X) can be denoted as 'p', then odds (logit) = p / (1-p)\n",
    "# it has similar interpretation as 'Linear Regression', for example, in lecture slides we have seen by how much 1-unit (1) of Bills (X) may increase/decrease the Tips (y)\n",
    "# however, this was more straight-forward in 'Linear Regression' since the relationship between 'predictor' (X) and the response variable (y) was regressed with linear activation function.\n",
    "\n",
    "# In logistic regression, we used non-linear activation function - so this relationship between 'predictor' (X) and response variable (y) are not linear.\n",
    "# we try to find how much 1-unit increase (e.g., say RM - average number of rooms predictor variable) will increase/decrease the odds - this will be the following:\n",
    "# exp(weight associated with RM) - RM is the 5th index inside the weight coef_\n",
    "# you can find one detailed explanation here: https://stats.stackexchange.com/questions/29325/what-is-the-difference-between-linear-regression-and-logistic-regression\n",
    "# the computed weights are for standardised features - needs to be scaled by std (standard deviation)\n",
    "print('The increase in odds by increasing 1-unit of average number of rooms (predictor RM) should be: {:.5f}'.format(np.exp((grid.best_estimator_.coef_[0][5]/np.sqrt(sc.var_[5])))))\n",
    "# we can actually verify it by taking one record, and computing p/(1-p) using the model for both original RM and new (RM+1)  \n",
    "orig_prob = grid.predict_proba(X_test[10].reshape(1, -1))  # if it is a single record, requires reshaping\n",
    "# the features were standardised by (x - u) / s by StandardScaler() - documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# increasing x by 1 will mean increasing standardised feature by 1/s\n",
    "X_test[10][5] = X_test[10][5] + (1/np.sqrt(sc.var_[5]))\n",
    "new_prob = grid.predict_proba(X_test[10].reshape(1, -1))\n",
    "print('The computed gain using the probabilities: {:.5f}'.format((new_prob[0, 1]/new_prob[0, 0])/(orig_prob[0, 1]/orig_prob[0, 0])))\n",
    "print('Means we gain more than 8 times odds of  being an Expensive house by just increasing 1-unit of average number of rooms (RM feature)\\nSimilar analysis can be performed regarding other features as well.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "We should have some ideas by now that the learnt parameters are nothing but the model parameters [weights] which were computed using an optimisation algorithm [solver]\n",
    "on a loss function [the loss function preferrably should be convex to ENSURE reaching globally optimum weights]. We discussed one solver in lecture notes: Gradient Descent.\n",
    "If the loss function is not convex, the ML algorithm can converge to a local optimum. But remember, it may not be always possible to find convex loss function for all the ML algorithms. Some 'solvers' try to take this into consideration, and still try to find the best possible weights! In the lecture slides, you were asked to research on the various solvers that are available as 'options' in scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>\n",
    "\n",
    "1. What do you feel about the model's performance looking at the various evaluation metrics?<br/>\n",
    "2. Which metric can be considered as the estimator's performance indicator (accuracy/recall/precision/f1/ROC)?<br/>\n",
    "2. Do change the 'scoring' metric of GridSearchCV to observe the changes in evaluaton metrics.<br/>\n",
    "4. You should try to optimise the hyper-parameters of any ML algorithm for a given use-case - one simple example is provided here. EDA can provide valuable insights in terms of ideas of which hyper-parameters can be important.\n",
    "5. What do you feel about the feature RM's importance in predicting the house prices looking at the interpretation inside 'Inference Probabilties' section?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
